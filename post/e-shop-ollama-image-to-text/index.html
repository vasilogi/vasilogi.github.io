<!doctype html>
<html lang="en-us"><head><script src="/livereload.js?mindelay=10&amp;v=2&amp;port=1313&amp;path=livereload" data-no-instant defer></script>
    <title>Ataraxia</title>
    <meta charset="utf-8">
    <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
    <meta name="description" content="" />

    
    
    
    <link rel="stylesheet" href="../../css/theme.min.css">

    
    
    

    
  
    
      <script async src="https://www.googletagmanager.com/gtag/js?id=G-SKJNMNQZ5R"></script>
      <script>
        var doNotTrack = false;
        if ( false ) {
          var dnt = (navigator.doNotTrack || window.doNotTrack || navigator.msDoNotTrack);
          var doNotTrack = (dnt == "1" || dnt == "yes");
        }
        if (!doNotTrack) {
          window.dataLayer = window.dataLayer || [];
          function gtag(){dataLayer.push(arguments);}
          gtag('js', new Date());
          gtag('config', 'G-SKJNMNQZ5R');
        }
      </script>
    
  


</head>
<body>
        <div id="content" class="mx-auto"><header class="container mt-sm-5 mt-4 mb-4 mt-xs-1">
    <div class="row">
        
        <div class="col-sm-4 col-12 text-sm-right text-center pt-sm-4">
            <a href="../../" class="text-decoration-none">
                <img id="home-image" class="rounded-circle"
                    
                        
                            src="../../images/profile.jpg"
                        
                    
                />
            </a>
        </div>
        <div class="col-sm-8 col-12 text-sm-left text-center">
        
            <h2 class="m-0 mb-2 mt-4">
                <a href="../../" class="text-decoration-none">
                    
                        Ioannis Vasilopoulos
                    
                </a>
            </h2>
            <p class="text-muted mb-1">
                
                    AI Solutions Engineer
                
            </p>
            <ul id="nav-links" class="list-inline mb-2">
                
                
                    <li class="list-inline-item">
                        <a class="badge badge-white " href="../../about/" title="About">About</a>
                    </li>
                
                    <li class="list-inline-item">
                        <a class="badge badge-white " href="../../post/" title="Posts">Posts</a>
                    </li>
                
                    <li class="list-inline-item">
                        <a class="badge badge-white " href="../../categories/" title="Categories">Categories</a>
                    </li>
                
            </ul>
            <ul id="nav-social" class="list-inline">
                
                    <li class="list-inline-item mr-3">
                        <a href="http://github.com/vasilogi" target="_blank">
                            <i class="fab fa-github fa-1x text-muted"></i>
                        </a>
                    </li>
                
                    <li class="list-inline-item mr-3">
                        <a href="https://www.linkedin.com/in/vasilogi/" target="_blank">
                            <i class="fab fa-linkedin-in fa-1x text-muted"></i>
                        </a>
                    </li>
                
                    <li class="list-inline-item mr-3">
                        <a href="mailto:iovannis@outlook.com" target="_blank">
                            <i class="fas fa-at fa-1x text-muted"></i>
                        </a>
                    </li>
                
            </ul>
        </div>
    </div>
    <hr />
</header>
<div class="container">
    <div class="pl-sm-2">
        <div class="mb-3">
            <h3 class="mb-0">Customise a Multimodal AI for Generating E-Shop Image Descriptions</h3>
            
            <small class="text-muted">Published November 30, 2024</small>
        </div>

        <article>
            <p>Imagine you&rsquo;re an e-shop owner who regularly receives new items from vendors that need to be listed in your online store. This process involves several manual steps, with writing marketing descriptions for each item being the most time-consuming task. To automate this process, various solutions have been considered, and a <a href="https://cloud.google.com/use-cases/multimodal-ai">Multimodal AI model</a> appears to be an excellent solution. These Deep Learning models can process information from multiple modalities, such as images and text simultaneously.</p>
<p>As with most technology decisions, you face the classic dilemma: build your own solution using open-source materials or opt for a pay-as-you-go service from providers like ChatGPT or Claude.ai. You can find numerous articles explaining the <a href="https://www.linkedin.com/pulse/saas-vs-custom-software-solutions-which-best-your-project-1uf2c/">differences between SaaS and custom software solutions</a> to guide your decision. Simply put, building your own solution might be appropriate if you have a GPU-equipped computer, are cost-conscious, prioritize security and privacy, can tolerate some downtime, and enjoy hands-on development. All necessary components for such solutions are freely available and supported by a large community.</p>
<p>As you may know, Generative AI technologies—including development, hosting, and scaling—evolve rapidly. What you build today might be superseded by better and more cost-effective solutions tomorrow. Therefore, the approach presented here is just one of many possible solutions. To begin, follow the previous <a href="https://vasilogi.github.io/post/llama-openwebui-on-windows/">guide to install Ollama and Open WebUI</a>.</p>
<p>For this project, we&rsquo;ll use <a href="https://ollama.com/library/llava">LLaVA</a>, an Ollama-compatible model. The 7B parameters version of LLaVA proved sufficient for my use case. Pull it from the registry using:</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-bash" data-lang="bash"><span style="display:flex;"><span>ollama pull llava:7b
</span></span></code></pre></div><p>After running Open WebUI using the provided docker-compose file, you should be able to access it at <code>http://localhost:3030/</code>.</p>
<p>To customise this model, we need to write a <a href="https://promptmetheus.com/resources/llm-knowledge-base/system-message">system message</a> that sets the context and establishes the model&rsquo;s role. For our e-shop use case, we need a system message that configures an AI assistant specifically for writing product descriptions for educational supplies, with precise parameters of 80 words in 3-4 sentences. The message should include comprehensive guidelines about what to include (materials, features, benefits) and what to avoid (technical jargon, pricing), along with specific style requirements. You can find the <a href="https://github.com/vasilogi/eshop-product-descriptions">used system message</a> on my GitHub.</p>
<p>There are two methods to customize a base model: through Open WebUI&rsquo;s interface or by <a href="https://github.com/ollama/ollama/blob/main/docs/modelfile.md">building a new model</a> with Ollama. Create a new model via Open WebUI is fairly easy and intuitive. While creating a model via Open WebUI is straightforward—simply visit <code>Workspace &gt; Models</code> and click the <code>+</code> icon to create your model based on any installed Ollama model—I recommend using Ollama&rsquo;s model building approach for greater agility, despite Open WebUI&rsquo;s import/export capabilities for configuration sharing and backup.</p>
<p>First, obtain the base Modelfile for LLaVA by executing:</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-bash" data-lang="bash"><span style="display:flex;"><span>ollama show llava:7b --modelfile
</span></span></code></pre></div><p>Copy its contents and add your custom system message. The <a href="https://github.com/vasilogi/eshop-product-descriptions/blob/main/Modelfile">complete Modelfile</a> for this use case is available on my GitHub. This approach allows you to track improvements to your Modelfile and system message as you optimize the model&rsquo;s performance.</p>
<blockquote>
<p>Using a Modelfile instead of Open WebUI customization is preferable because Ollama serves as the actual model server, which becomes important when extending your solution, such as implementing batch requests to the Ollama API.</p>
</blockquote>
<p>To create your new model using the Modelfile, run:</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-bash" data-lang="bash"><span style="display:flex;"><span>ollama create eshop_assistant -f Modelfile
</span></span></code></pre></div><p>Verify the model&rsquo;s presence in your local registry with:</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-bash" data-lang="bash"><span style="display:flex;"><span>ollama list
</span></span></code></pre></div><p>Finally, launch Open WebUI, start a new chat, select the <code>eshop_assistant</code> model, and upload an image to generate a product description.</p>
<p><img src="images/gif_prompt.gif" alt="gif_load_image"></p>
<p><img src="images/model_output.png" alt="model_output"></p>

        </article>
    </div>

    

            </div>
        </div><footer class="text-center pb-1">
    <small class="text-muted">
        
            &copy; 2024, Ioannis Vasilopoulos
        
        <br>
        Powered by <a href="https://gohugo.io/" target="_blank">Hugo</a>
        and <a href="https://github.com/austingebauer/devise" target="_blank">Devise</a>
    </small>
</footer>
</body>
</html>
